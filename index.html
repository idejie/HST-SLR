<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>HST-SLR: Hierarchical Sub-action Tree  for Continuous Sign Language Recognition</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">HST-SLR: Hierarchical Sub-action Tree  for Continuous Sign Language Recognition</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/idejie" target="_blank">Dejie Yang</a><sup>1</sup>,</span>
                <span class="author-block">
                  Zhu Xu<sup>1</sup>,</span>
                  <span class="author-block">
                   Xinjie Gao<sup>1</sup>,
                <span class="author-block">
                  <a href="http://www.csyangliu.com/" target="_blank">Yang Liu</a><sup>1,2*</sup>
                </span>
                
                  </div>
                  <br>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block"> <sup>1</sup>Wangxuan Institute of Computer Technology, Peking University 
                      <br> <sup>2</sup>State Key Laboratory of General Artificial Intelligence, BIGAI
                      <br>
                      <br>ICME2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/html/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Arxiv(Coming Soon)</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/KAD.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Slides</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/idejie/HST-SLR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv(Coming Soon)</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/teaser.png" alt="MY ALT TEXT"/>
    
      <h2 class="content" style="text-align: center;">
        <b>Sign language videos display a hierarchy of semantic information, from high-level events (glosses) to fine-grained subactions. However, existing datasets lack detailed annotations for these subactions, posing challenges forimproving the layered understanding of sign language content. To address this,we leverage large language models (LLMs) to generate precise and meaningful descriptions of subactions, thereby enhancing the hierarchical understanding of sign language videos.</b></h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Continuous sign language recognition (CSLR) aims to transcribe untrimmed videos into glosses, which are typically textual words. Recent studies indicate that the lack of large datasets and precise annotations has become a bottleneck for CSLR due to insufficient training data. To address this, some works have developed cross-modal solutions to align visual and textual modalities. However, they typically extract textual features from glosses without fully utilizing their knowledge. In this paper, we propose the Hierarchical Sub-action Tree (HST), termed HST-CSLR, to efficiently combine gloss knowledge with visual representation learning. By incorporating gloss-specific knowledge from large language models, our approach leverages textual information more effectively. Specifically, we construct an HST for textual information representation, aligning visual and textual modalities step-by-step and benefiting from the tree structure to reduce computational complexity. Additionally, we impose a contrastive alignment enhancement to bridge the gap between the two modalities. Experiments on four datasets (PHOENIX-2014, PHOENIX-2014T, CSL-Daily, and Sign Language Gesture) demonstrate the effectiveness of our HST-CSLR. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->




<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Framework</h2>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/frame.png" alt="MY ALT TEXT"/>
    
      <h2 class="content has-text-justified" style="text-align: center;">
        Our proposed HST-CSLR framework. To explore the fine-grained sub-action information, we use an LLM to generate detailed descriptions for each gloss and construct a Hierarchical Sub-action Tree (HST). An optimal path search algorithm is applied to integrate semantic and temporal information in sub-action sequence, and a hierarchical cross-modal alignment enhances visual-textual consistency using activated tree nodes.</h2>
  </div>
</section>
<!-- End teaser video -->




<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Results</h2>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table1.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table2.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table3.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table4.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table5.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table6.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table7.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/table8.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/prompt.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <div class="hero-body" style="text-align: center;">
      <img src="static/images/Visual.png" alt="MY ALT TEXT" width="100%"/>
    </div>
    <!-- <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>1.Grounding accuracy (%) on Nr3D, Sr3D and ScanRefer.</b> The best and second-best results are in bold and underlined.
      </h2>
      <img src="static/images/table2.png" alt="MY ALT TEXT" width="100%"/>
    
      
    </div>
    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>2. Dense Captioning results on Scan2Cap dataset.</b> “C” stands for “CIDEr”, “B-4” for “BLEU-4”, “M” for “METEOR”, and “R” for
          “ROUGE”, respectively. “@0.25” and “@0.5” represent the 3D IoU between the predicted and annotated box. The best results are in bold and underlined.
      </h2>
      <img src="static/images/table3.png" alt="MY ALT TEXT" width="100%"/>
    
      
    </div>
    <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified">
        <b>3. Answer accuracy on ScanQA </b>using object proposals from Mask3D. Each entry denotes “test w/ object” and second-best results are in bold and underlined.
      </h2>
      <img src="static/images/table4.png" alt="MY ALT TEXT" width="100%"/>
    
      
    </div> -->
    <!-- <div class="hero-body" style="text-align: center;">
      <h2 class="content has-text-justified" style="text-align: center;">
        <b>4. Comparisons with other methods on 100DOH.</b> We bold the best results and underline the second best ones.
      </h2>
      <img src="static/images/100DOH.png" alt="MY ALT TEXT" width="50%"/> -->
    

      <!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Slides</h2>

      <iframe  src="static/pdfs/KAD.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->
      
    </div>
  </div>
</section>









<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
        HST-SLR,
        title     = {HST-SLR: Hierarchical Sub-action Tree  for Continuous Sign Language Recognition},
        author    = {Dejie Yang, Zhu Xu, Xinjie Gao, Yang Liu},
        booktitle = {IEEE International Conference on Multimedia & Expo 2025, {ICME-25} },
        publisher = {IEEE},
        year      = {2025},
      }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
